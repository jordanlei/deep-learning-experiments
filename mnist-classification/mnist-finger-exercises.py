import torch
import torchvision
import matplotlib.pyplot as pyplot
from time import time
from torchvision import datasets, transforms
from torch import nn, optim
from torch.utils.data import DataLoader, random_split
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision.transforms as transforms
from torch.autograd import Variable

device =  torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

#%%
def get_dataloaders(train_set, test_set, batch_size = 64):
    train_set = random_split(train_set, [int(0.6*len(train_set)), len(train_set) - int(0.6*len(train_set))])
    params= {'batch_size': batch_size, 'shuffle': True}
    train_load= DataLoader(train_set[0], **params)
    val_load= DataLoader(train_set[1], batch_size = len(train_set[1]), shuffle = True)
    test_load= DataLoader(test_set, batch_size = len(test_set), shuffle= True)
    
    return train_load, val_load, test_load


def display_images(loader, number=5):
    for i, data in enumerate(loader, 0):
        inputs, labels = data
        inputs, labels = Variable(inputs), Variable(labels)
        
        inputs = inputs.to(device)
        labels = labels.to(device)
        
        plt.figure()
        plt.imshow(inputs[0][0])
        plt.show()
        print(labels[0])
        
        if i>number:
            break
        
#%% Class Feedforward Network takes an iage and number of classes
class FeedForwardNet(nn.Module):

    def __init__(self, img_width, img_height, num_classes):
        super(FeedForwardNet, self).__init__()
        in_size= img_width * img_height
        layers = [120, 60]
        self.features= nn.Sequential(
            nn.Linear(in_size, layers[0]),
            nn.ReLU(),
            nn.Linear(layers[0], layers[1]),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(layers[1], num_classes),
            nn.Softmax()
        )
        

    def forward(self, x):
        x = self.features(x)
        return x
    
#%% Class Runner runs the actual network itself
class Runner():
    def __init__(self, net, criterion, optimizer):
        self.net = net.to(device)
        self.criterion = criterion
        self.optimizer = optimizer
        
    def train(self, train_load, val_load, epochs = 100, log_every = 10):
        step = 0
        for epoch in range(epochs):
            running_count = 0 
            running_correct = 0
            for i, data in enumerate(train_load, 0):
                inputs, labels = data
                inputs, labels = Variable(inputs), Variable(labels)
                
                inputs = inputs.to(device)
                labels = labels.to(device)
                
                inputs = inputs.view(inputs.shape[0], -1)
                
                #predictions generated by the network
                y_pred = self.net(inputs)
                
                #criterion evaluated on predictions compared with labels
                loss = self.criterion(y_pred, labels)
                
                #zero gradient the optimizer
                self.optimizer.zero_grad()
                
                #backpropagation
                loss.backward()
                
                #weight update
                self.optimizer.step()
                
                pred = self.net(inputs)
                step_loss = self.criterion(pred, labels)
                _, pred = torch.max(pred, 1)
                
                step_correct = int((pred==labels).sum())
                running_correct = running_correct + step_correct
                running_count = running_count + labels.size(0)
                                
                if (step % log_every==0):
                    print("[Epoch %s] [Step %s] Accuracy: %.04f Loss: %.04f"% 
                          (epoch, step, running_correct/running_count, step_loss))
                
                step = step + 1
                
            for i, data in enumerate(val_load, 0):
                inputs, labels = data
                inputs, labels = Variable(inputs), Variable(labels)
                
                inputs = inputs.to(device)
                labels = labels.to(device)
                
                inputs = inputs.view(inputs.shape[0], -1)
                
                pred = self.net(inputs)
                _, pred = torch.max(pred, 1)
                
                val_correct = int((pred==labels).sum())
                val_count = labels.size(0)
                print("Val accuracy: %s"%
                      (val_correct/val_count))
                
    def test(self, test_load):
        for i, data in enumerate(test_load, 0):
            inputs, labels = data
            inputs, labels = Variable(inputs), Variable(labels)
            
            inputs = inputs.to(device)
            labels = labels.to(device)
            
            inputs = inputs.view(inputs.shape[0], -1)
            
            pred = self.net(inputs)
            _, pred = torch.max(pred, 1)
            
            test_correct = int((pred==labels).sum())
            test_count = labels.size(0)
            print("Test accuracy: %s"%
                  (test_correct/test_count))
        return pred, labels, test_correct, test_count
                        
#%%
def main():
    train_set = torchvision.datasets.MNIST(root= "/data", train= True, download= True, transform = transforms.ToTensor())
    test_set = torchvision.datasets.MNIST(root= "/data", train= False, download= True, transform = transforms.ToTensor())

    train_load, val_load, test_load = get_dataloaders(train_set, test_set)
    
    network = FeedForwardNet(28, 28, 10)                

    #specify loss
    criterion= nn.CrossEntropyLoss()
    
    #specify optimization
    optimizer= optim.Adam(network.parameters(), lr= 0.001)
    
    #specify runner
    runner = Runner(network, criterion, optimizer)

    #train, test network
    runner.train(train_load, val_load, epochs = 5)
    runner.test(test_load)
    
    
if __name__== "__main__":
  main()
                    